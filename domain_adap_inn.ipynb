{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: generate hsi dummy data => run inference.py => will produce output.\n",
    "#  then replace their data with my data in same folder structure and run inference.py again. Need to have data_stats.json and mapping.json as well\n",
    "\n",
    "#current: error File \"C:/Users/jedwinne/udt/Lib/site-packages/pytorch_lightning/core/saving.py\", line 169, in _load_state\n",
    "#     keys = obj.load_state_dict(checkpoint[\"state_dict\"], strict=strict)\n",
    "#            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "#   File \"C:/Users/jedwinne/udt/Lib/site-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n",
    "#     raise RuntimeError('Error(s) in loading state_dict for {}:/n/t{}'.format(\n",
    "# RuntimeError: Error(s) in loading state_dict for GanCondinitionalDomainAdaptationINNHSI:\n",
    "#         size mismatch for model.module_list.0.w_perm: copying a param with shape torch.Size([100, 100]) from checkpoint, the shape in current model is torch.Size([100]).\n",
    "\n",
    "\n",
    "# https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-27/issue-07/074702/3D-printed-tissue-simulating-phantoms-for-near-infrared-fluorescence-imaging/10.1117/1.JBO.27.7.074702.full?SSO=1\n",
    "\n",
    "# => check wat er in C:/Users/jedwinne/OneDrive - UGent/PhD-UG-8HYNGY3/Data/publication_data_dreher_DT/publication_data/simulated_data/HSI_Data/intermediates/semantic_v2/train\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# https://github.com/IMSY-DKFZ/UDT-cINN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(spectra):\n",
    "    norms = np.linalg.norm(spectra,ord=1, axis=1,keepdims=True)\n",
    "    spectra = spectra / norms    \n",
    "    return spectra\n",
    "\n",
    "folder = 'C:/Users/jedwinne/OneDrive - UGent/Documents/GitHub/PersonalProjects/Oxygenation_AI/real_data/'\n",
    "\n",
    "#phantom\n",
    "phantom = np.load(folder + 'tissue_phantoms.npy')\n",
    "spectra_phantom = phantom[:,0:16]\n",
    "label_phantom = phantom[:,-1]\n",
    "spectra_phantom = normalization(spectra_phantom)\n",
    "phantom_tissue_label = np.zeros(len(spectra_phantom))\n",
    "\n",
    "def sample_per_label(spectra, labels, tissue_label, n_samples):\n",
    "    unique_labels = np.unique(labels)\n",
    "    indices = []\n",
    "\n",
    "    for label in unique_labels:\n",
    "        label_indices = np.where(labels == label)[0]\n",
    "        sample_indices = np.random.choice(label_indices, n_samples, replace=False)\n",
    "        indices.extend(sample_indices)\n",
    "\n",
    "    sampled_spectra = spectra[indices]\n",
    "    sampled_labels = labels[indices]\n",
    "    sampled_tissue_label = tissue_label[indices]\n",
    "    \n",
    "    return sampled_spectra, sampled_labels, sampled_tissue_label\n",
    "\n",
    "spectra_phantom, label_phantom, phantom_tissue_label = sample_per_label(spectra_phantom, label_phantom, phantom_tissue_label, 500)\n",
    "\n",
    "#liver\n",
    "liver = np.load(folder + 'liver.npy')\n",
    "spectra_liver = liver[:,0:16]\n",
    "spectra_liver = normalization(spectra_liver)\n",
    "liver_tissue_label = np.ones(len(spectra_liver)) * 1\n",
    "\n",
    "#heart\n",
    "heart = np.load(folder + 'heart_wall.npy')\n",
    "spectra_heart = heart[:,0:16]\n",
    "spectra_heart = normalization(spectra_heart)\n",
    "heart_tissue_label = np.ones(len(spectra_heart)) * 2\n",
    "\n",
    "#coronary artery\n",
    "ca= np.load(folder + 'coronary_artery.npy')\n",
    "spectra_ca = ca[:,0:16]\n",
    "spectra_ca = normalization(spectra_ca)\n",
    "ca_tissue_label = np.ones(len(spectra_ca)) * 3\n",
    "\n",
    "#GI tract\n",
    "gi = np.load(folder + 'gi_tract.npy')\n",
    "spectra_gi = gi[:,0:16]\n",
    "spectra_gi = normalization(spectra_gi)\n",
    "gi_tissue_label = np.ones(len(spectra_gi)) * 4\n",
    "\n",
    "# my simulations\n",
    "df = np.load('C:/Users/jedwinne/OneDrive - UGent/Documents/GitHub/PersonalProjects/Oxygenation_AI/dataframes_adapted/simulations_10k.npy')\n",
    "simulation_spectra = df[:,0:16]\n",
    "simulation_labels = df[:,16:]\n",
    "simulation_spectra = normalization(simulation_spectra)\n",
    "\n",
    "# Ayala\n",
    "ayala_spectra = np.load('C:/Users/jedwinne/OneDrive - UGent/Documents/GitHub/PersonalProjects/Oxygenation_AI/dataframes_adapted/simulations_ayala.npy')\n",
    "ayala_spectra = normalization(ayala_spectra)\n",
    "ayala_labels = np.load('C:/Users/jedwinne/OneDrive - UGent/Documents/GitHub/PersonalProjects/Oxygenation_AI/dataframes_adapted/ayala_labels.npy') * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split in train, test and validation sets\n",
    "\n",
    "# synthetic data\n",
    "from sklearn.model_selection import train_test_split\n",
    "save_folder = \"C:/Users/jedwinne/OneDrive - UGent/PhD-UG-8HYNGY3/Data/publication_data_dreher_DT/publication_data/simulated_data/HSI_Data/intermediates/semantic_v2_jens/\"\n",
    "train_data, temp_data = train_test_split(simulation_spectra, test_size=0.3, random_state=42)\n",
    "np.save(save_folder + 'train_synthetic_unique/' + 'train.npy', train_data)\n",
    "\n",
    "validation_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "np.save(save_folder + 'val_synthetic_unique/' + 'val.npy', validation_data)\n",
    "np.save(save_folder + 'test_synthetic_unique/' + 'test.npy', test_data)\n",
    "\n",
    "#real data\n",
    "real_data = np.concatenate((spectra_phantom, spectra_liver, spectra_heart, spectra_ca, spectra_gi), axis=0)\n",
    "real_data_labels = np.concatenate((phantom_tissue_label, liver_tissue_label, heart_tissue_label, ca_tissue_label, gi_tissue_label), axis=0)\n",
    "\n",
    "train_data, temp_data, = train_test_split(real_data, test_size=0.3, random_state=42)\n",
    "np.save(save_folder + 'train/' + 'train.npy', train_data)\n",
    "validation_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "np.save(save_folder + 'val/' + 'val.npy', validation_data)\n",
    "np.save(save_folder + 'test/' + 'test.npy', test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
